{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33eecf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d2e3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import *\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "to_pil_image = transforms.ToPILImage()\n",
    "\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13505cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels, size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        self.mha = nn.MultiheadAttention(channels, 4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        attention_value = attention_value + x\n",
    "        attention_value = self.ff_self(attention_value) + attention_value\n",
    "        return attention_value.swapaxes(2, 1).view(-1, self.channels, self.size, self.size)\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            return F.gelu(x + self.double_conv(x))\n",
    "        else:\n",
    "            return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x,t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels, in_channels // 2),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_x,t):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=3, time_dim=256, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        self.inc = DoubleConv(c_in, 32)\n",
    "        self.down1 = Down(32, 64)\n",
    "        self.sa1 = SelfAttention(64, 16)\n",
    "        self.down2 = Down(64, 128)\n",
    "        self.sa2 = SelfAttention(128, 8)\n",
    "        self.down3 = Down(128, 256)\n",
    "        self.sa3 = SelfAttention(256, 4)\n",
    "\n",
    "        self.bot1 = DoubleConv(256, 256)\n",
    "        #self.bot2 = DoubleConv(256, 256)\n",
    "        self.bot3 = DoubleConv(256, 128)\n",
    "\n",
    "        self.up1 = Up(256, 128)\n",
    "        self.sa4 = SelfAttention(128,8)\n",
    "        self.up2 = Up(192, 64)\n",
    "        self.sa5 = SelfAttention(64, 16)\n",
    "        self.up3 = Up(96, 32)\n",
    "        self.sa6 = SelfAttention(32, 32)\n",
    "        self.outc = nn.Conv2d(32, c_out, kernel_size=1)#nn.Sequential(nn.Conv2d(32, c_out, kernel_size=1),\n",
    "                                 #nn.Sigmoid())\n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x,t):\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        t = self.pos_encoding(t, self.time_dim)\n",
    "\n",
    "        x1 = self.inc(x)   # B x 32 x 32 x 32\n",
    "        x2 = self.down1(x1,t) #  B x 64 x  16 x 16\n",
    "        x2 = self.sa1(x2)     #  B x 64 x  16 x 16\n",
    "        x3 = self.down2(x2,t) #  B x 128 x  8 x 8\n",
    "        x3 = self.sa2(x3)      #  B x 128 x  8 x 8\n",
    "        x4 = self.down3(x3,t) #  B x 256 x  4 x 4\n",
    "        x4 = self.sa3(x4)    #  B x 256 x  4 x 4\n",
    "\n",
    "        x4 = self.bot1(x4)   #  B x 256 x  4 x 4\n",
    "        #x4 = self.bot2(x4)   #  B x 256 x  4 x 4\n",
    "        x4 = self.bot3(x4)   #  B x 128 x  4 x 4\n",
    "\n",
    "        x = self.up1(x4, x3,t) #  B x 128 x  8x 8\n",
    "        x = self.sa4(x)        #  B x 128 x  8x 8\n",
    "        x = self.up2(x, x2,t)  #  B x 64 x  8 x 8\n",
    "        x = self.sa5(x)   #  B x 64 x  16 x 16\n",
    "        x = self.up3(x, x1,t) #  B x 64 x  64 x 64\n",
    "        x = self.sa6(x)   #  B x 32 x  32 x 32\n",
    "        output = self.outc(x)  #  B x 3 x  32 x 32\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f97e3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DKGM(nn.Module):\n",
    "    def __init__(self,device,image_channel=3,T=20):\n",
    "        super(DKGM, self).__init__()\n",
    "        \n",
    "\n",
    "        self.unet=UNet()\n",
    "\n",
    "        self.T=T\n",
    "\n",
    "        self.device=device\n",
    "\n",
    "       \n",
    "    def forward(self,x):\n",
    "\n",
    "        \n",
    "        #initial encoding\n",
    "        t0=torch.zeros(x.size(dim=0),device=self.device)\n",
    "\n",
    "        reconstruction=self.unet(x,t0)\n",
    "\n",
    "        total_recons=reconstruction\n",
    "        bias=-reconstruction+x\n",
    "        recons_bias=torch.zeros_like(x, device=self.device)\n",
    "        a_i=0\n",
    "        #sequence of bias encoding +decoding \n",
    "        for i in range(self.T):\n",
    "\n",
    "            \n",
    "\n",
    "            bias=bias-recons_bias*a_i\n",
    "\n",
    "            recons_bias=self.unet(bias,t0+i+1)\n",
    "            a_i=1/(i+1.0)\n",
    "            total_recons+=recons_bias*a_i\n",
    "\n",
    "\n",
    "        return total_recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e5aeae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def final_lossDKGM(mse_loss):\n",
    "\n",
    "    return mse_loss\n",
    "\n",
    "def model_trainDKGM(model,dataloader,dataset,device,optimizer,criterion,a=1):\n",
    "    model.train()\n",
    "    running_loss=0.0\n",
    "    counter=0\n",
    "    for i, data in tqdm(enumerate(dataloader),total=int(len(dataset)/dataloader.batch_size)):\n",
    "        counter+=1\n",
    "        data=data[0]\n",
    "        data=data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        posterior_X=model(data+a*torch.randn_like(data))\n",
    "\n",
    "        bce_loss= criterion(posterior_X,data)\n",
    "        \n",
    "        loss=final_lossEVAE(bce_loss)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    train_loss=running_loss/counter\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def model_validateDKGM(model,dataloader,dataset,device,optimizer,criterion,a=1):\n",
    "    model.eval()\n",
    "    running_loss=0.0\n",
    "    counter=0\n",
    "    with torch.no_grad():\n",
    "        for i,data in tqdm(enumerate(dataloader),total=int(len(dataset)/dataloader.batch_size)):\n",
    "            counter+=1\n",
    "            data=data[0]\n",
    "            data=data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            posterior_X=model(data+a*torch.randn_like(data))\n",
    "\n",
    "            bce_loss= criterion(posterior_X,data)\n",
    "            loss=bce_loss\n",
    "            running_loss+=loss.item()\n",
    "\n",
    "            if i==int(len(dataset)/dataloader.batch_size)-1:\n",
    "                recon_images=posterior_X\n",
    "                #noisez_image=data+noise\n",
    "        valid_loss=running_loss/counter\n",
    "        return valid_loss,recon_images#,noisez_image\n",
    "        #return valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b980d",
   "metadata": {},
   "source": [
    "# training DKGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b72a8856",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "latent_dim=64\n",
    "lr=0.0003\n",
    "epochs=20\n",
    "batch_size=128\n",
    "\n",
    "DKGMmodel =DKGM(T=0,device=device).to(device) #UNet().to(device)\n",
    "# lr=0.0003\n",
    "# epochs=50\n",
    "# batch_size=100\n",
    "\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize( [0.5, 0.5, 0.5]  ,  [0.5, 0.5, 0.5]  )])\n",
    "\n",
    "#training set transforms.Resize((32,32)),\n",
    "train_set=torchvision.datasets.CIFAR10(root='./',train=True,download=False,transform=transform)\n",
    "train_loader=torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "#test set\n",
    "test_set=torchvision.datasets.CIFAR10(root='./',train=False,download=False,transform=transform)\n",
    "test_loader=torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "optimizerDKGM=optim.Adam(DKGMmodel.parameters(),lr=lr)\n",
    "\n",
    "criterion=nn.MSELoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2994894",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_imagesDKGM=[]\n",
    "train_lossDKGM=[]\n",
    "valid_lossDKGM=[]\n",
    "\n",
    "grid_imagesDKGM=[]\n",
    "train_lossDKGM=[]\n",
    "valid_lossDKGM=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch{epoch+1} of {epochs}\")\n",
    "    \n",
    "    train_epoch_lossDKGM=model_trainDKGM(DKGMmodel,train_loader,train_set,device,optimizerDKGM,criterion,a=1,m=1)\n",
    "    valid_epoch_lossDKGM,recon_images=model_validateDKGM(DKGMmodel,test_loader,test_set,device,optimizerDKGM,criterion,a=1,m=1)\n",
    "    train_lossEVAE.append(train_epoch_lossEVAE)\n",
    "    valid_lossEVAE.append(valid_epoch_lossEVAE)\n",
    "\n",
    "    save_reconstructed_images((recon_images+1)/2,epoch+1)\n",
    "    print(f\"train loss:{train_epoch_lossDKGM:.4f}\")\n",
    "    print(f\"valid loss:{valid_epoch_lossDKGM:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d804be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_blur = transforms.Compose([\n",
    "    transforms.GaussianBlur(kernel_size=(5, 5), sigma=1.2)\n",
    "])\n",
    "\n",
    "\n",
    "DKGMmodel2 =DKGM(T=3,device=device).to(device) \n",
    "\n",
    "\n",
    "optimizerDKGM2=optim.Adam(DKGMmodel2.parameters(),lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c03406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:30,  3.47it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537.6349635108952\n",
      "Epoch2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:27,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752.6624822049132\n",
      "Epoch3 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:28,  3.49it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452.93304634704396\n",
      "Epoch4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:25,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313.1172520301316\n",
      "Epoch5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:25,  3.51it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.47046061471266\n",
      "Epoch6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:26,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665.2660412632802\n",
      "Epoch7 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:26,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322.23521321809835\n",
      "Epoch8 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:24,  3.51it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241.51578839497924\n",
      "Epoch9 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:26,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346.42595096131737\n",
      "Epoch10 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:26,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.2015727281723\n",
      "Epoch11 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:25,  3.51it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480.2368717547494\n",
      "Epoch12 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:25,  3.51it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320.79379919714756\n",
      "Epoch13 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:26,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208.01759601966432\n",
      "Epoch14 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:25,  3.51it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.83927621188565\n",
      "Epoch15 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:24,  3.52it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.0261060064295\n",
      "Epoch16 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:26,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366.6763487344206\n",
      "Epoch17 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:25,  3.51it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224.04745191499657\n",
      "Epoch18 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:26,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.20750932943645\n",
      "Epoch19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:26,  3.50it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288.74982692550105\n",
      "Epoch20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [07:27,  3.49it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.53096119593292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "min_loss=1000000000\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch{epoch+1} of {epochs}\")\n",
    "    DKGMmodel2.train()\n",
    "    running_loss=0.0\n",
    "    counter=0\n",
    "    for i, data in tqdm(enumerate(train_loader),total=int(len(train_set)/train_loader.batch_size)):\n",
    "        counter+=1\n",
    "        data=data[0]\n",
    "        data=data.to(device)\n",
    "        optimizerDKGM2.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        posterior_Xt_1=DKGMmodel2(transform_blur(data))\n",
    "\n",
    "\n",
    "        bce_loss= criterion(posterior_Xt_1,data)\n",
    "\n",
    "        loss=final_lossDKGM(bce_loss)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizerDKGM2.step()\n",
    "\n",
    "\n",
    "\n",
    "        running_loss+=loss.item()#+errD_fake.item()+errD_real.item()\n",
    "\n",
    "    train_loss=running_loss/counter\n",
    "    if train_loss<min_loss :\n",
    "        min_loss=train_loss\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': DKGMmodel2.state_dict(),\n",
    "        'optimizer_state_dict': optimizerDKGM2.state_dict(),\n",
    "        'loss': loss,\n",
    "        # ... any other relevant variables ...\n",
    "    }, 'DKGM_boost_cifar10_best_12.pt')\n",
    "    print(train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7176f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1895eb9",
   "metadata": {},
   "source": [
    "#Reconstructed image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e7bf55",
   "metadata": {},
   "source": [
    "## Second stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7710d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAEmodel.eval()\n",
    "DKGMmodel.eval()\n",
    "DKGMmodel2.eval()\n",
    "running_loss=0.0\n",
    "counter=0\n",
    "#test set\n",
    "tota_sharpDKGM=0.0\n",
    "tota_sharpDKGM=0.0\n",
    "from scipy import signal\n",
    "#laplace\n",
    "kernel=np.array([[0 ,1, 0],[1, -4,1],[0, 1 ,0]])\n",
    "\n",
    "\n",
    "from torcheval.metrics import FrechetInceptionDistance\n",
    "\n",
    "fidDKGM = FrechetInceptionDistance(device=device)            \n",
    "transform_grayscale=transforms.Grayscale(num_output_channels=1)\n",
    "\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "inception = InceptionScore(normalize=True)   \n",
    "with torch.no_grad():\n",
    "    for i,data in tqdm(enumerate(train_loader),total=int(len(train_set)/train_loader.batch_size)):\n",
    "        counter+=1\n",
    "        data=data[0]\n",
    "        data=data.to(device)\n",
    "        #optimizerVAE.zero_grad()\n",
    "        optimizerDKGM.zero_grad()\n",
    "\n",
    "        noise=torch.randn_like(data)\n",
    "\n",
    "        state1=DKGMmodel(data+0.5*noise)\n",
    "        reconstruction_DKGM=DKGMmodel2(state1)\n",
    "\n",
    "        image_grid_DKGM=transform_grayscale(torch.clamp((reconstruction_DKGM+1.0)/2,0,1)).detach().cpu()\n",
    "        for j in range(data.size(dim=0)):\n",
    "\n",
    "\n",
    "            sharpnessDKGM = np.var(np.abs(signal.convolve2d(image_grid_DKGM[j][0], kernel, mode=\"same\")))\n",
    "            tota_sharpDKGM+=sharpnessDKGM\n",
    "\n",
    "        inception.update(torch.clamp((reconstruction_DKGM.cpu()+1.0)/2,0.0,1.0))\n",
    "        \n",
    "        \n",
    "        fidEVAE.update(torch.clamp((data+1.0)/2,0,1), is_real=True)\n",
    "        fidEVAE.update(torch.clamp((reconstruction_DKGM+1.0)/2,0,1), is_real=False)\n",
    "        \n",
    "\n",
    "lossDKGM=fidDKGM.compute()\n",
    "Is=inception.compute()\n",
    "# print(f\"FIDVAE: {float(lossVAE)}\")\n",
    "# print(f\"shaprnessVAE:{tota_sharpVAE/len(test_set):.4f}\")\n",
    "print(f\"FIDDKGM: {float(lossDKGM)}\")\n",
    "print(f\"shaprnessDKGM:{tota_sharpDKGM/len(train_set):.4f}\")\n",
    "print(f\"IS (mean): {float(Is[0])}\")\n",
    "print(f\"IS (std): {float(Is[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4563886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
