{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33eecf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2e3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import *\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "to_pil_image = transforms.ToPILImage()\n",
    "\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13505cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, channels, size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        self.mha = nn.MultiheadAttention(channels, 4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.channels, self.size * self.size).swapaxes(1, 2)\n",
    "        x_ln = self.ln(x)\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        attention_value = attention_value + x\n",
    "        attention_value = self.ff_self(attention_value) + attention_value\n",
    "        return attention_value.swapaxes(2, 1).view(-1, self.channels, self.size, self.size)\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            return F.gelu(x + self.double_conv(x))\n",
    "        else:\n",
    "            return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x,t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            DoubleConv(in_channels, in_channels, residual=True),\n",
    "            DoubleConv(in_channels, out_channels, in_channels // 2),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_x,t):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=3, time_dim=256, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        self.inc = DoubleConv(c_in, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.sa1 = SelfAttention(128, 64)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.sa2 = SelfAttention(256, 32)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.sa3 = SelfAttention(512, 16)\n",
    "\n",
    "        self.bot1 = DoubleConv(512, 512)\n",
    "        #self.bot2 = DoubleConv(256, 256)\n",
    "        self.bot3 = DoubleConv(512, 256)\n",
    "\n",
    "        self.up1 = Up(512, 128)\n",
    "        self.sa4 = SelfAttention(256,8)\n",
    "        self.up2 = Up(256, 64)\n",
    "        self.sa5 = SelfAttention(128, 16)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.sa6 = SelfAttention(32, 64)\n",
    "        self.outc = nn.Conv2d(64, c_out, kernel_size=1)#nn.Sequential(nn.Conv2d(32, c_out, kernel_size=1),\n",
    "                                 #nn.Sigmoid())\n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x,t):\n",
    "        t = t.unsqueeze(-1).type(torch.float)\n",
    "        t = self.pos_encoding(t, self.time_dim)\n",
    "        \n",
    "        #print(x.size())\n",
    "                           #Bx C x H x W\n",
    "        x1 = self.inc(x)   # B x 64 x 128 x 128\n",
    "        \n",
    "        x2 = self.down1(x1,t) #  B x 128 x  64 x 64\n",
    "        \n",
    "        #x2 = self.sa1(x2)     #  B x 128 x  32 x 32\n",
    "        #print(x2.size())\n",
    "        x3 = self.down2(x2,t) #  B x 256 x  16 x 16\n",
    "        \n",
    "        #x3 = self.sa2(x3)      #  B x 256 x  16 x 16\n",
    "        x4 = self.down3(x3,t) #  B x 512 x 8 x 8\n",
    "        #x4 = self.sa3(x4)    #  B x 512 x  8 x 8\n",
    "        \n",
    "        x4 = self.bot1(x4)   #  B x 512 x  8 x 8\n",
    "        #x4 = self.bot2(x4)   #  B x 256 x  4 x 4\n",
    "        x4 = self.bot3(x4)   #  B x 128 x  4 x 4\n",
    "        \n",
    "        x = self.up1(x4, x3,t) #  B x 256 x  8x 8\n",
    "        \n",
    "        #x = self.sa4(x)        #  B x 256 x  8x 8\n",
    "        x = self.up2(x, x2,t)  #  B x 128 x  16 x 16\n",
    "        #x = self.sa5(x)   #  B x 128 x  16 x 16\n",
    "        x = self.up3(x, x1,t) #  B x 64 x  32 x 32\n",
    "        #x = self.sa6(x)   #  B x 64 x  64 x 64\n",
    "        output = self.outc(x)  #  B x 3 x  128 x 128\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97e3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DKGM(nn.Module):\n",
    "    def __init__(self,device,T=20):\n",
    "        super(DKGM, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.unet=UNet()\n",
    "        \n",
    "\n",
    "        self.T=T\n",
    "\n",
    "        self.device=device\n",
    "\n",
    "       \n",
    "    def forward(self,x):\n",
    "\n",
    "        \n",
    "        #initial encoding\n",
    "        t0=torch.zeros(x.size(dim=0),device=self.device)\n",
    "\n",
    "        #initial decoding\n",
    "        reconstruction=self.unet(x,t0)\n",
    "\n",
    "        total_recons=reconstruction\n",
    "        bias=-reconstruction+x\n",
    "        recons_bias=torch.zeros_like(x, device=self.device)\n",
    "        a_i=0\n",
    "        #sequence of bias encoding +decoding \n",
    "        for i in range(self.T):\n",
    "\n",
    "            \n",
    "\n",
    "            bias=bias-recons_bias*a_i\n",
    "\n",
    "            recons_bias=self.unet(bias,t0+i+1)\n",
    "            a_i=1/(i+1.0)\n",
    "            total_recons+=recons_bias*a_i\n",
    "\n",
    "\n",
    "        return total_recons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5aeae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def final_lossDKGM(mse_loss):\n",
    "\n",
    "    return mse_loss\n",
    "\n",
    "def model_trainDKGM(model,dataloader,dataset,device,optimizer,criterion,a=1):\n",
    "    model.train()\n",
    "    running_loss=0.0\n",
    "    counter=0\n",
    "    for i, data in tqdm(enumerate(dataloader),total=int(len(dataset)/dataloader.batch_size)):\n",
    "        counter+=1\n",
    "        data=data[0]\n",
    "        data=data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        posterior_X=model(data+a*torch.randn_like(data))\n",
    "\n",
    "        bce_loss= criterion(posterior_X,data)\n",
    "        \n",
    "        loss=final_lossEVAE(bce_loss)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    train_loss=running_loss/counter\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def model_validateDKGM(model,dataloader,dataset,device,optimizer,criterion,a=1):\n",
    "    model.eval()\n",
    "    running_loss=0.0\n",
    "    counter=0\n",
    "    with torch.no_grad():\n",
    "        for i,data in tqdm(enumerate(dataloader),total=int(len(dataset)/dataloader.batch_size)):\n",
    "            counter+=1\n",
    "            data=data[0]\n",
    "            data=data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            posterior_X=model(data+a*torch.randn_like(data))\n",
    "\n",
    "            bce_loss= criterion(posterior_X,data)\n",
    "            loss=bce_loss\n",
    "            running_loss+=loss.item()\n",
    "\n",
    "            if i==int(len(dataset)/dataloader.batch_size)-1:\n",
    "                recon_images=posterior_X\n",
    "                #noisez_image=data+noise\n",
    "        valid_loss=running_loss/counter\n",
    "        return valid_loss,recon_images#,noisez_image\n",
    "        #return valid_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b980d",
   "metadata": {},
   "source": [
    "# training DKGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72a8856",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "latent_dim=64\n",
    "lr=0.0003\n",
    "epochs=10\n",
    "batch_size=32\n",
    "\n",
    "DKGMmodel =DKGM(T=0,device=device).to(device) #UNet().to(device)\n",
    "\n",
    "\n",
    "transform= transforms.Compose([\n",
    "    transforms.CenterCrop((160, 160)),\n",
    "    transforms.Resize([128, 128]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#training set transforms.Resize((32,32)),\n",
    "train_set=torchvision.datasets.CelebA(root='./',split='train',download=False,transform=transform)\n",
    "train_loader=torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "#test set\n",
    "test_set=torchvision.datasets.CelebA(root='./',split='valid',download=False,transform=transform)\n",
    "test_loader=torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=True)\n",
    "#optimizerVAE=optim.Adam(VAEmodel.parameters(),lr=lr)\n",
    "optimizerDKGM=optim.Adam(DKGMmodel.parameters(),lr=lr)\n",
    "#optimizerD=optim.Adam(EVAEmodel.parameters(),lr=lr)\n",
    "criterion=nn.MSELoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2994894",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_imagesDKGM=[]\n",
    "train_lossDKGM=[]\n",
    "valid_lossDKGM=[]\n",
    "\n",
    "grid_imagesDKGM=[]\n",
    "train_lossDKGM=[]\n",
    "valid_lossDKGM=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch{epoch+1} of {epochs}\")\n",
    "    \n",
    "    train_epoch_lossDKGM=model_trainDKGM(DKGMmodel,train_loader,train_set,device,optimizerDKGM,criterion,a=1,m=1)\n",
    "    valid_epoch_lossDKGM,recon_images=model_validateDKGM(DKGMmodel,test_loader,test_set,device,optimizerDKGM,criterion,a=1,m=1)\n",
    "    train_lossEVAE.append(train_epoch_lossEVAE)\n",
    "    valid_lossEVAE.append(valid_epoch_lossEVAE)\n",
    "\n",
    "    save_reconstructed_images((recon_images+1)/2,epoch+1)\n",
    "    print(f\"train loss:{train_epoch_lossDKGM:.4f}\")\n",
    "    print(f\"valid loss:{valid_epoch_lossDKGM:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d804be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_blur = transforms.Compose([\n",
    "    transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.8,1.2))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "DKGMmodel2 =DKGM(T=3,device=device).to(device) #UNet().to(device)\n",
    "\n",
    "\n",
    "optimizerDKGM2=optim.Adam(DKGMmodel2.parameters(),lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8c03406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:03:44,  1.85it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080.2590066159205\n",
      "Epoch2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:02:18,  1.86it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219.6051408356927\n",
      "Epoch3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:02:22,  1.86it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.79823357803367\n",
      "Epoch4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:02:18,  1.86it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.32189697246033\n",
      "Epoch5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:02:16,  1.86it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.239646034591782\n",
      "Epoch6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:03:00,  1.85it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.842965366574138\n",
      "Epoch7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:12:01,  1.77it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.316985123792128\n",
      "Epoch8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:03:08,  1.85it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2605974176049894\n",
      "Epoch9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:03:06,  1.85it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.669031417296021\n",
      "Epoch10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20347it [3:03:06,  1.85it/s]                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.758881488965174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "min_loss=1000000000\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch{epoch+1} of {epochs}\")\n",
    "    DKGMmodel2.train()\n",
    "    running_loss=0.0\n",
    "    counter=0\n",
    "    for i, data in tqdm(enumerate(train_loader),total=int(len(train_set)/train_loader.batch_size)):\n",
    "        counter+=1\n",
    "        data=data[0]\n",
    "        data=data.to(device)\n",
    "        optimizerDKGM2.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        posterior_Xt_1=DKGMmodel2(transform_blur(data))\n",
    "\n",
    "\n",
    "        bce_loss= criterion(posterior_Xt_1,data)\n",
    "\n",
    "        loss=final_lossDKGM(bce_loss)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizerDKGM2.step()\n",
    "\n",
    "\n",
    "\n",
    "        running_loss+=loss.item()#+errD_fake.item()+errD_real.item()\n",
    "\n",
    "    train_loss=running_loss/counter\n",
    "    if train_loss<min_loss :\n",
    "        min_loss=train_loss\n",
    "        torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': DKGMmodel2.state_dict(),\n",
    "        'optimizer_state_dict': optimizerDKGM2.state_dict(),\n",
    "        'loss': loss,\n",
    "        # ... any other relevant variables ...\n",
    "    }, 'DKGM_boost_CelebA128_best.pt')\n",
    "    print(train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7710d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAEmodel.eval()\n",
    "DKGMmodel.eval()\n",
    "DKGMmodel2.eval()\n",
    "running_loss=0.0\n",
    "counter=0\n",
    "#test set\n",
    "tota_sharpDKGM=0.0\n",
    "tota_sharpDKGM=0.0\n",
    "from scipy import signal\n",
    "#laplace\n",
    "kernel=np.array([[0 ,1, 0],[1, -4,1],[0, 1 ,0]])\n",
    "\n",
    "\n",
    "from torcheval.metrics import FrechetInceptionDistance\n",
    "\n",
    "fidDKGM = FrechetInceptionDistance(device=device)            \n",
    "transform_grayscale=transforms.Grayscale(num_output_channels=1)\n",
    "\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "inception = InceptionScore(normalize=True)   \n",
    "with torch.no_grad():\n",
    "    for i,data in tqdm(enumerate(train_loader),total=int(len(train_set)/train_loader.batch_size)):\n",
    "        counter+=1\n",
    "        data=data[0]\n",
    "        data=data.to(device)\n",
    "        #optimizerVAE.zero_grad()\n",
    "        optimizerDKGM.zero_grad()\n",
    "\n",
    "        noise=torch.randn_like(data)\n",
    "\n",
    "        state1=DKGMmodel(data+1*noise)\n",
    "        reconstruction_DKGM=DKGMmodel2(state1)\n",
    "\n",
    "        image_grid_DKGM=transform_grayscale(torch.clamp(reconstruction_DKGM,0,1)).detach().cpu()\n",
    "        for j in range(data.size(dim=0)):\n",
    "\n",
    "\n",
    "            sharpnessDKGM = np.var(np.abs(signal.convolve2d(image_grid_DKGM[j][0], kernel, mode=\"same\")))\n",
    "            tota_sharpDKGM+=sharpnessDKGM\n",
    "\n",
    "        inception.update(torch.clamp(reconstruction_DKGM.cpu(),0.0,1.0))\n",
    "        \n",
    "        \n",
    "        fidEVAE.update(torch.clamp(data,0,1), is_real=True)\n",
    "        fidEVAE.update(torch.clamp(reconstruction_DKGM,0,1), is_real=False)\n",
    "        \n",
    "\n",
    "lossDKGM=fidDKGM.compute()\n",
    "Is=inception.compute()\n",
    "# print(f\"FIDVAE: {float(lossVAE)}\")\n",
    "# print(f\"shaprnessVAE:{tota_sharpVAE/len(test_set):.4f}\")\n",
    "print(f\"FIDDKGM: {float(lossDKGM)}\")\n",
    "print(f\"shaprnessDKGM:{tota_sharpDKGM/len(train_set):.4f}\")\n",
    "print(f\"IS (mean): {float(Is[0])}\")\n",
    "print(f\"IS (std): {float(Is[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4563886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
